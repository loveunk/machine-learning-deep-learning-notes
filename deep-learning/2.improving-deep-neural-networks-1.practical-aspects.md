# 深度神经网络调参和优化

这个章节介绍神经网络的超参数 (Hyper-parameters) 调优，如何构建数据，以及算法优化。

## 1. 深度学习的实践层面

### 训练集、验证集、测试集

#### 应用型机器学习是快速迭代的过程

在配置训练、验证和测试数据集的过程中做出正确决策会在很大程度上帮助大家创建高效的神经网络。训练神经网络时，我们需要做出很多决策，包括但不限于：

- 神经网络分多少层
- 每层含有多少个隐藏单元
- 学习速率是多少
- 各层采用哪些激活函数

创建开发过程中，我们不可能一开始就能准确地预测出这些信息和其他超级参数。实际上，应用型机器学习是一个高度迭代的过程，通常在项目启动时，我们会先有一个初步想法，比如构建一个含有特定层数，隐藏单元数或数据集个数等等的神经网络，然后编码，并尝试运行。通过运行和测试得到该神经网络运行结果，你可能会根据结果完善想法，改变策略，或者为了找到更好的神经网络不断迭代方案。

现如今，深度学习已经在自然语言处理(NLP)，计算机视觉(CV)，语音识别(Speech Recognition)以及结构化数据应用等众多领域取得巨大成功。结构化数据无所不包，从广告到网络搜索。其中网络搜索不仅包括网络搜索引擎，还包括购物网站，从所有根据搜索栏词条传输结果的网站。再到计算机安全，物流，比如判断司机去哪接送货，范围之广，不胜枚举。

我发现，可能有NLP方面的人才想踏足CV领域，或者经验丰富的语音识别专家想投身广告行业，又或者，有的人想从电脑安全领域跳到物流行业，在我看来，从一个领域或者应用领域得来的直觉经验，通常无法转移到其他应用领域，最佳决策取决于你所拥有的数据量，计算机配置中输入特征的数量，用GPU训练还是CPU，GPU和CPU的具体配置以及其他诸多因素。

目前为止，对于很多系统，即使是经验丰富的深度学习行家也不太可能一开始就预设出最匹配的超参数。所以说，应用深度学习是一个典型的迭代过程，需要多次循环往复，才能为应用程序找到一个称心的神经网络，因此循环该过程的效率是决定项目进展速度的一个关键因素，而创建高质量的**训练数据集 (Training set)**，**验证集 (Cross-validation set)**和**测试集 (Test set)**也有助于提高循环效率。

<p align="center">
<img src="https://raw.github.com/loveunk/deeplearning_ai_books/master/images/072653e2e9402d2857bfcb7b9f783a5c.png" />
</p>

#### 训练集、验证集、测试集

假设这是训练数据，我用一个长方形表示（如下图），通常会将这些数据划分成三部分：

* 训练集
* 交叉验证集（又称开发集 Development set/Dev set）
* 测试集

<p align="center">
<img src="https://raw.github.com/loveunk/deeplearning_ai_books/master/images/ebbfb8514ff5a983f41e938d5870b79d.png" />
</p>

接下来，我们开始对训练集执行算法，通过验证集或简单交叉验证集选择最好的模型，经过充分验证，我们选定了最终模型，然后就可以在测试集上进行评估了，这样可以在评估算法性能时不映入偏差。

在机器学习发展的小数据量时代，常见做法是将所有数据三七分，就是人们常说的70%训练集，30%测试集。如果明确设置验证集，也可以按照60%训练集，20%验证集和20%测试集来划分。这是前几年机器学习领域普遍认可的最好的实践方法。

但是在大数据时代，数据量可能是百万级别，那么验证集和测试集占数据总量的比例会趋向变得更小。因为验证集的目的就是验证不同的算法，检验哪种算法更有效。因此，验证集只要足够大到能评估不同的算法，比如2个甚至10个不同算法，并判断出哪种算法更有效就可以。因此验证集不用特别大，我们可能不需要拿出20%的数据作为验证集。

>  比如我们有100万条数据，那么取1万条数据便足以进行评估不同的算法，找出其中表现最好的1-2种。同样地，根据最终选择的分类器，测试集的主要目的是评估分类器的性能，所以如果拥有百万数据，只需要1000条数据，便足以评估单个分类器，并且准确评估该分类器的性能。假设有100万条数据，其中1万条作为验证集，1万条作为测试集，100万里取1万，比例是1%，即：训练集占98%，验证集和测试集各占1%。对于数据量过百万的应用，训练集可以占到99.5%，验证和测试集各占0.25%，或者验证集占0.4%，测试集占0.1%。

**总结一下**：在深度学习中，通常将样本分成训练集，验证集和测试集三部分。数据集规模相对较小，适用传统的划分比例，数据集规模较大的，验证集和测试集要小于数据总量的20%或10%。

#### 不一致的训练集和测试机分布

现代深度学习的另一个趋势是越来越多的人在训练和测试集分布不一致的情况下进行训练。假设你要构建一个用户可以上传大量图片的应用程序，目的是找出并呈现所有猫咪图片，可能你的用户都是爱猫人士，训练集可能是从网上下载的猫咪图片，而验证集和测试集是用户在这个应用上上传的猫的图片，就是说，训练集可能是从网络上抓下来的图片。而验证集和测试集是用户上传的图片。结果许多网页上的猫咪图片分辨率很高，很专业，后期制作精良，而用户上传的照片可能是用手机随意拍摄的，像素低，比较模糊，这两类数据有所不同。对这种情况，我建议**要确保验证集和测试集的数据来自同一分布**。因为你要用验证集来评估不同的模型，然后优化算法性能。

如果验证集和测试集来自同一个分布会很好，但由于深度学习算法需要大量的训练数据，为了获取更大规模的训练数据集，你可能会采用各种方法，例如，网页抓取。代价是训练集数据与验证集、测试集数据可能不是来自同一分布。但只要遵循这个经验法则，你就会发现机器学习算法会变得更快。

最后一点，就算**没有测试集也不要紧**，测试集的目的是对最终所选定的神经网络系统做出无偏估计，如果不需要无偏估计，也可以不设置测试集。所以如果只有验证集，没有测试集，我们要做的就是，在训练集上训练，尝试不同的模型框架，在验证集上评估这些模型，然后迭代并选出适用的模型。因为验证集中已经涵盖测试集数据，其不再提供无偏性能评估。当然，如果你不需要无偏估计，那就再好不过了。

在机器学习中，如果只有一个训练集和一个验证集，而没有独立的测试集，遇到这种情况，训练集还被人们称为训练集，而验证集则被称为测试集，不过在实际应用中，人们只是把测试集当成简单交叉验证集使用，并没有完全实现该术语的功能，因为他们把验证集数据过度拟合到了测试集中。如果某团队跟你说他们只设置了一个训练集和一个测试集，我会很谨慎，心想他们是不是真的有训练验证集，因为他们把验证集数据过度拟合到了测试集中，让这些团队改变叫法，改称其为“训练验证集”，而不是“训练测试集”，可能不太容易。即便我认为“训练验证集“在专业用词上更准确。实际上，如果你不需要无偏评估算法性能，那么这样是可以的。

所以说，搭建训练验证集和测试集能够加速神经网络的集成，也可以更有效地衡量算法地偏差和方差，从而帮助我们更高效地选择合适方法来优化算法。

### 偏差、方差 (Bias / Variance)

有经验的机器学习参与人员对偏差和方差都有深刻的理解。这两个概率很容易入门，但是却非常难精通。即自己认为已经理解了偏差和方差的基本概念，却总有一些出乎意料。关于深度学习的误差问题，另一个趋势是对偏差和方差的权衡研究甚浅，你可能听说过“偏差-方差困境”这个概念。在深度学习领域，我们会分别讨论偏差和方差，却很少谈及偏差和方差的权衡问题，下面来看一看。

<p align="center">
<img src="https://raw.github.com/loveunk/deeplearning_ai_books/master/images/e0ec4205933b7c2a9eaed9fbaa8d4afc.png" />
</p>

对于上图的数据集，如果给这个数据集拟合一条直线（下图左），可能得到一个逻辑回归拟合，但逻辑回归并不能很好拟合该数据，这是高偏差（**High bias**）的情况，我们称为“欠拟合”（**Underfitting**）。

相反的，如果拟合一个非常复杂的分类器，比如深度神经网络或含有隐藏单元的神经网络，可能就非常适用于这个数据集，但是这看起来也不是一种很好的拟合方式分类器方差较高（**High variance**），数据过度拟合（**Overfitting**）。

在两者之间，可能还有一些像图中这样的，复杂程度适中，数据拟合适度的分类器，这个数据拟合看起来更加合理，我们称之为“适度拟合”（**Just right**）是介于过度拟合和欠拟合中间的一类。

<p align="center">
<img src="https://raw.github.com/loveunk/deeplearning_ai_books/master/images/05ac08b96177b5d0aaae7b7bfea64f3a.png" />
</p>

对于Bias和Variance的解释，引用一张[知乎](https://www.zhihu.com/question/27068705)的解释图：

* 偏差Bias描述的是根据样本拟合出的模型的输出预测结果的期望与样本真实结果的差距
* 方差Variance描述的是样本上训练出来的模型在测试集上的表现

<p align="center">
<img src="img/bias.vs.variance.jpg" />
</p>
在上面的例子中，只有 _x<sub>1</sub>_ 和 _x<sub>2</sub>_ 两个特征的二维数据集中，可以容易地绘制数据，将偏差和方差可视化。但在多维空间数据中，绘制数据和可视化分割边界无法实现，但我们可以通过几个指标，来研究偏差和方差。

<p align="center">
<img src="https://raw.github.com/loveunk/deeplearning_ai_books/master/images/2efd9728b5f07f914903dde309167a5d.png" />
</p>

沿用猫狗图片分类这个例子，左边一张是猫咪图片，右边不是。理解偏差和方差的两个关键数据是训练集误差（**Train set error**）和验证集误差（**Dev set error**），为了方便论证，假设我们可以辨别图片中的猫咪，用肉眼识别几乎是不会出错的。

通过查看训练集误差和验证集误差，便可以诊断算法是否具有高方差。也就是说衡量训练集和验证集误差就可以得出不同结论。有下面几个例子：

<p align="center">
<img src="https://raw.github.com/loveunk/deeplearning_ai_books/master/images/c61d149beecddb96f0f93944320cf639.png" />
</p>

* 假定训练集误差是1%，为了方便论证，假定验证集误差是11%，可以看出训练集设置得非常好，而验证集设置相对较差，可能过拟合训练集，在某种程度上，验证集并没有充分利用交叉验证集的作用，像这种情况，我们称之为“高方差”。

* 假设训练集误差是15%，验证集误差是16%，假设该案例中人的错误率几乎为0%。算法并没有在训练集中得到很好训练，如果训练数据的拟合度不高，就是数据欠拟合，就可以说这种算法偏差比较高。相反，它对于验证集产生的结果却是合理的，验证集中的错误率只比训练集的多了1%，所以这种算法偏差高，因为它甚至不能拟合训练集。

* 训练集误差是15%，偏差相当高，但是，验证集的评估结果更糟糕，错误率达到30%，在这种情况下，会认为这种算法偏差高，因为它在训练集上结果不理想，而且方差也很高，这是方差偏差都很糟糕的情况。

* 训练集误差是0.5%，验证集误差是1%，用户看到这样的结果会很开心，猫咪分类器只有1%的错误率，偏差和方差都很低。

有一点先在这个简单提一下，这些分析都是基于假设预测的，假设人眼辨别的错误率接近0%。一般来说，最优误差也被称为贝叶斯误差。上面的例子中，最优误差接近0%，如果最优误差或贝叶斯误差非常高，比如15%。再看看这个分类器（训练误差15%，验证误差16%），15%的错误率对训练集来说也是非常合理的，偏差不高，方差也非常低。


当所有分类器都不适用时，如何分析偏差和方差呢？比如，图片很模糊，即使是人眼，或者没有系统可以准确无误地识别图片，在这种情况下，最优误差会更高，那么分析过程就要做些改变了，暂时先不讨论这些细微差别，重点是通过查看训练集误差，我们可以判断数据拟合情况，至少对于训练数据是这样，可以判断是否有偏差问题，然后查看错误率有多高。当完成训练集训练，开始使用验证集验证时，我们可以判断方差是否过高，从训练集到验证集的这个过程中，我们可以判断方差是否过高。


以上分析的前提都是假设基本误差很小，训练集和验证集数据来自相同分布，如果没有这些假设作为前提，分析过程更加复杂，将会在稍后讨论。

上面讲了高偏差和高方差的情况，大家应该对优质分类器有了一定的认识，偏差和方差都高是什么样子呢？这种情况对于两个衡量标准来说都是非常糟糕的（下图第三列）。

<p align="center">
<img src="https://raw.github.com/loveunk/deeplearning_ai_books/master/images/f8fdbf9ed01b8634573125e0fb2ca860.png" />
</p>

我们之前讲过，下图这样的分类器，会产生高偏差，因为它的数据拟合度低，像这种接近线性的分类器，数据拟合度低。

<p align="center">
<img src="https://raw.github.com/loveunk/deeplearning_ai_books/master/images/e9451f36e8baa41b74c95d9a09b0f028.png" />
</p>

但是如果我们稍微改变一下分类器，我用紫色笔画出，它会过度拟合部分数据，用紫色线画出的分类器具有高偏差和高方差，偏差高是因为它几乎是一条线性分类器，并未拟合数据。

![](https://github.com/loveunk/deeplearning_ai_books/raw/master/images/6e86aa7d9b21b1a49bf4a084c7503527.png)

这种二次曲线能够很好地拟合数据（下图虚线）。

![](https://github.com/loveunk/deeplearning_ai_books/raw/master/images/67dc5997a956314e238e6fc362f9883d.png)

紫色曲线中间部分灵活性非常高，却过度拟合了这两个样本。蓝色直线分类器偏差很高，因为它几乎是线性的。

![](https://github.com/loveunk/deeplearning_ai_books/raw/master/images/6bf7e092ddf93104ea64a5ddecbb7c6d.png)

总结一下，我们讲了如何通过分析在训练集上训练算法产生的误差和验证集上验证算法产生的误差来诊断算法是否存在高偏差和高方差，是否两个值都高，或者两个值都不高，根据算法偏差和方差的具体情况决定接下来你要做的工作。

### 机器学习基础

下面是在训练神经网络时用到地基本方法。初始模型训练完成后，

1. 首先检查算法的偏差（Bias）：
   * **如果偏差较高，那么需要选择一个新的网络**，比如含有更多隐藏层或者隐藏单元的网络，或者尝试更先进的优化算法，或其他方法。
     * 以后我们会看到许多不同的神经网络架构，或许你能找到一个更合适的网络架构。可能有用，也可能没用，不过采用规模更大的网络通常都会有所帮助。
     * 不断尝试新方法，直到解决掉偏差问题。这是最低标准，直到可以拟合数据为止，至少能够拟合训练集。
2. 一旦偏差降低到可以接受的数值，检查方差有没有问题。
   * 为了评估方差，要查看验证集性能，我们能从一个性能理想的训练集推断出验证集的性能是否也理想。
   * **如果方差高，最好的办法是采用更多数据**。如果你能做到，会有一定的帮助.
   * 有时候，我们无法获得更多数据，**也可以尝试通过正则化来减少过拟合**。
   * 需要反复尝试，**如果能找到更合适的神经网络框架，有时可能会同时减少方差和偏差**。如何实现呢？想系统地说出做法很难，总之就是不断重复尝试，直到找到一个低偏差，低方差的框架，这时你就成功了。

<p align="center">
<img src="https://raw.github.com/loveunk/deeplearning_ai_books/master/images/L2_week1_8.png" />
</p>

有需要注意两点：

1. 高偏差和高方差是不同的情况，后续要尝试的方法也可能完全不同，我通常会用训练验证集来诊断算法是否存在偏差或方差问题，然后根据结果选择尝试部分方法。

   * 举个例子，如果算法存在高偏差问题，准备更多训练数据其实也没什么用处，至少这不是更有效的方法，所以大家要清楚存在的问题是偏差还是方差，还是两者都有问题，明确这一点有助于我们选择出最有效的方法。

2. 在机器学习的初期阶段，关于所谓的偏差方差权衡的讨论屡见不鲜，原因是我们能尝试的方法有很多。可以增加偏差，减少方差，也可以减少偏差，增加方差。

   * 在深度学习的早期阶段，我们没有太多工具可以做到只减少偏差或方差却不影响到另一方。

   * 但在当前的深度学习和大数据时代，只要持续训练一个更大的网络，只要准备了更多数据，那么也并非只有这两种情况。我们假定是这样，**只要正则适度，通常构建一个更大的网络便可以在不影响方差的同时减少偏差，而采用更多数据通常可以在不过多影响偏差的同时减少方差**。

     这两步实际要做的工作是：训练网络，选择网络或者准备更多数据，现在我们有工具可以做到在减少偏差或方差的同时，不对另一方产生过多不良影响。我觉得这就是深度学习对监督式学习大有裨益的一个重要原因，也是我们不用太过关注如何平衡偏差和方差的一个重要原因，但有时我们有很多选择，减少偏差或方差而不增加另一方。最终，我们会得到一个非常规范化的网络。从下节开始，将讲解正则化，训练一个更大的网络几乎没有任何负面影响，而训练一个大型神经网络的主要代价也只是计算时间，前提是网络是比较规范化的。

### 正则化（Regularization）

深度学习可能存在过拟合问题——高方差，通常有两个解决方法：

1. 准备更多的数据
   * 更多的数据是非常可靠的方法，但你可能无法准备足够的训练数据，或者获取数据的成本很高
2. 正则化
   * 正则化有助于避免过度拟合，或者减少网络误差，下面来讲讲正则化的作用原理

#### 逻辑回归中的正则化

我们用逻辑回归来讲解，求成本函数 _J_ 的最小值，_J_定义的是成本函数。参数包含一些训练数据和不同数据中个体预测的损失， _w_ 和 _b_ 是逻辑回归的两个参数， _w ∈ R<sup>n<sub>x</sub></sup>_ 是一个多维度参数矢量， _b ∈ R_ 是一个实数。

在逻辑回归函数中加入正则化，只需添加参数λ，也就是正则化参数。 _(<sup>λ</sup>/<sub>2m</sub>)_ 乘以 _w_ 的L2范数的平方， _||w||<sup>2</sup><sub>2</sub>_ 是欧几里德范数的平方，等于 _w<sub>j</sub>_ （ _j_ 值从1到 _n<sub>x</sub>_ ）平方的和，也可表示为 _w<sup>T</sup>w_ ，也就是向量参数 _w_ 的欧几里德范数（L2范数）的平方，此方法称为 **_L2_ 正则化**，因为这里用了向量参数 _w_ 的 _L2_ 范数。（如下图）

<p align="center">
<img src="https://raw.github.com/loveunk/deeplearning_ai_books/master/images/fa185e95684bbe6c0e9100164aff2ee5.png" />
</p>
为什么只正则化参数 _w_ ？而没考虑参数 _b_ 呢？

* 可以这么做，只是习惯省略掉了，因为 _w_ 通常是一个高维参数矢量，已经可以表达高偏差问题， _w_ 可能包含有很多参数，我们不可能拟合所有参数，而 _b_ 只是单个数字。所以绝大多数的参数在 _w_ 中，而不是在 _b_ 中。如果加了参数 _b_ ，其实也没太大影响，因为 _b_ 只是众多参数中的一个，所以通常省略不计，如果你想加上这个参数，也没问题。

<p align="center">
<img src="https://raw.github.com/loveunk/deeplearning_ai_books/master/images/84c4e19130a91a09120087dd704bbaa4.png" />
</p>
_L2_ 正则化是最常见的正则化类型。你可能也知道 _L1_ 正则化：

* _L1_ 正则化加的不是 _L2_ 范数，而是正则项 _(<sup>λ</sup>/<sub>m</sub>)_ 乘以 _Σ<sub>j=1</sub><sup>n<sub>x</sub></sup>|w|_ ， _Σ<sub>j=1</sub><sup>n<sub>x</sub></sup>|w|_ 也被称为参数 _w_ 向量的 _L1_ 范数，无论分母是 _m_ 还是 _2m_ ，它都是一个比例常量。

> 如果用的是 _L1_ 正则化， _w_ 最终会是稀疏的，也就是说 _w_ 向量中有很多0，有人说这样有利于压缩模型，因为集合中参数均为0，存储模型所占用的内存更少。实际上，虽然 _L1_ 正则化使模型变得稀疏，却没有降低太多存储内存，所以我认为这并不是使用 _L1_ 正则化的目的，至少不是为了压缩模型，人们在训练网络时，越来越倾向于使用 _L2_ 正则化。

_λ_ 是正则化参数，我们通常使用验证集或交叉验证集来配置这个参数，尝试各种各样的数据，寻找最好的参数，我们要考虑训练集之间的权衡，把参数设置为较小值，这样可以避免过拟合，所以λ是另外一个需要调整的超级参数。

> 顺便说一下，为了方便写代码，在Python编程语言中， _λ_ 是一个保留字段，编写代码时，我们删掉 _a_ ，写成 _lambd_ ，以免与Python中的保留字段冲突

#### 神经网络中的正则化

上面讲了在逻辑回归函数中实现 _L2_ 正则化的过程，那么在神经网络中如何实现 _L2_ 正则化？

神经网络含有一个成本函数，该函数包含 _W<sup>[1]</sup>_ ， _b<sup>[1]</sup>_ 到 _W<sup>[l]</sup>_ ， _b<sup>[l]</sup>_ 所有参数，字母 _L_ 是神经网络所含的层数，因此成本函数等于 _m_ 个训练样本损失函数的总和乘以 _(<sup>λ</sup>/<sub>m</sub>)_ ，正则项为 _(<sup>λ</sup>/<sub>2m</sub>)Σ<sub>1</sub><sup>L</sup>||W<sup>[l]</sup>||<sup>2</sup>_ ，我们称 _||W<sup>[l]</sup>||<sup>2</sup>_ 为范数平方，这个矩阵范数 _||W<sup>[l]</sup>||<sup>2</sup>_ （即平方范数），被定义为矩阵中所有元素的平方求和。

<p align="center">
<img src="https://latex.codecogs.com/gif.latex?\begin{align*}&space;J(w^{[1]},b^{[1]},...,w^{[l]},b^{[l]})&=&space;\dfrac{1}{m}\sum_{i=1}^{m}\mathcal{L}(\hat{y}^{(i)},{y}^{(i)})&plus;&space;\dfrac{\lambda}{m}\sum_{l=1}^{L}\left\|w^{[l]}\right\|_F^2\\&space;\left\|w^{[l]}\right\|_F^2&=\sum_{i=1}^{n^{[l-1]}}\sum_{j=1}^{n^{[l]}}(w_{ij}^{[l]})^2&space;\end{align*}" title="\begin{align*} J(w^{[1]},b^{[1]},...,w^{[l]},b^{[l]})&= \dfrac{1}{m}\sum_{i=1}^{m}\mathcal{L}(\hat{y}^{(i)},{y}^{(i)})+ \dfrac{\lambda}{m}\sum_{l=1}^{L}\left\|w^{[l]}\right\|_F^2\\ \left\|w^{[l]}\right\|_F^2&=\sum_{i=1}^{n^{[l-1]}}\sum_{j=1}^{n^{[l]}}(w_{ij}^{[l]})^2 \end{align*}" />
</p>

上述公式中有两个求和公式，第一个求和符号其值 _i_ 从1到 _n<sup>[l-1]</sup>_ ，第二个其 _J_ 值从1到 _n<sup>[l]</sup>_ ，因为 _W_ 是一个 _(n<sup>[l]</sup>×n<sup>[l-1]</sup>)_ 的多维矩阵， _n<sup>[l]</sup>_ 表示 _l_ 层单元的数量， _n<sup>[l-1]</sup>_ 表示第 _l-1_ 层隐藏单元的数量。

该矩阵范数被称作“弗罗贝尼乌斯范数 (Frobenius Norm)”，用下标 _F_ 标注，鉴于线性代数中一些原因，我们不称之为“矩阵 _L2_ 范数”，而称它为“弗罗贝尼乌斯范数”。矩阵 _L2_ 范数听起来更自然，按照惯例，我们称之为“弗罗贝尼乌斯范数”，**它表示一个矩阵中所有元素的平方和。**

**该如何使用该范数实现梯度下降呢？**

用Backprop计算出 _dW_ 的值，backprop会给出 _J_ 对 _W_ 的偏导数，实际上是 _W<sup>[l]</sup>_ ，把 _W<sup>[l]</sup>_ 替换为 _W<sup>[l]</sup>_ 减去学习率_α_乘以 _dW_ 。回顾一下此前的Backprop的公式：

* _dw<sup>[l]</sup> = (from backprop)_ 
* _w<sup>[l]</sup> = w<sup>[l]</sup> - α dw<sup>[l]</sup>_ 

在之前公式额外增加的正则化项

*  _dw<sup>[l]</sup> = (from backprop) + (<sup> λ </sup>/<sub> m </sub>)w<sup>[l]</sup>_ 

现在我们要做的就是给 _dW_ 加上这一项 _(<sup>λ</sup>/<sub>m</sub>)W<sup>[l]</sup>_ ，然后计算这个更新项，使用新定义的 _dW<sup>[l]</sup>_ ，它的定义含有相关参数代价函数导数和，以及最后添加的额外正则项，这也是 _L2_ 正则化有时被称为“权重衰减”的原因。

我们用 _dW<sup>[l]</sup>_ 的定义替换此处的 _dW<sup>[l]</sup>_ ，可以看到， _W<sup>[l]</sup>_ 的定义被更新为 _W<sup>[l]</sup>_ 减去学习率 _α_ 乘以backprop再加上 _(<sup> λ </sup>/<sub> m </sub>)W<sup>[l]</sup>_ 。

* _w<sup>[l]</sup> = w<sup>[l]</sup> - α [(from backprop) + (<sup> λ </sup>/<sub> m </sub>)w<sup>[l]</sup>]_ 
* _w<sup>[l]</sup> = w<sup>[l]</sup> - (<sup> α λ </sup>/<sub> m </sub>)w<sup>[l]</sup> - α(from backprop)_

该正则项说明，不论 _W<sup>[l]</sup>_ 是什么，我们都试图让它变得更小，实际上，相当于我们给矩阵W乘以 _(1  -  α(<sup> λ </sup>/<sub> m </sub>))_ 倍的权重，矩阵 _W_ 减去 _α(<sup> λ </sup>/<sub> m </sub>)_ 倍的它，也就是用这个系数 _(1 - α(<sup> λ </sup>/<sub> m </sub>))_ 乘以矩阵 _W_ ，该系数小于1，因此 _L2_ 范数正则化也被称为“权重衰减”，因为它就像一般的梯度下降， _W_ 被更新为少了 _α_ 乘以backprop输出的最初梯度值，同时 _W_ 也乘以了这个系数，这个系数_(1 - <sup> α λ </sup>/<sub> m </sub>)_小于1，因此 _L2_ 正则化也被称为“权重衰减”。

* w<sup>[l]</sup> = (1 - <sup> α λ </sup>/<sub> m </sub>)w<sup>[l]</sup> - α(from backprop)


之所以叫它“权重衰减”是因为这两项相等，权重指标乘以了一个小于1的系数。

以上就是在神经网络中应用 _L2_ 正则化的过程，你可能会问，为什么正则化可以预防过拟合，会在下节讲，同时直观感受一下正则化是如何预防过拟合的。

### 为什么正则化有利于预防过拟合？

### Dropout 正则化

### 理解 Dropout

### 其他正则化方法

### 归一化输入

### 梯度消失/梯度爆炸

### 神经网络的权重初始化

### 梯度的数值逼近

### 梯度检验

### 梯度检验应用的注意事项